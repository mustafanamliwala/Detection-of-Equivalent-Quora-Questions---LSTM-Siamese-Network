{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves as an example on how a Siamese LSTM Neural Network can be implemented to analyse semantic similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk \n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def text_to_wordlist(text, remove_stopwords, stem_words):\n",
    "    \"\"\" \n",
    "    This function was adapoted from \n",
    "    https://www.kaggle.com/currie32/quora-question-pairs/the-importance-of-cleaning-text\n",
    "    \n",
    "    Description:\n",
    "        - Clean the text, with the option to remove stopwords and to stem words.\n",
    "        - Convert words to lower case and split them \n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    text : str\n",
    "           question string \n",
    "    remove_stopwords : bool\n",
    "                       if True --> removes stopwords, if False --> does not remove stopwords \n",
    "    stem_words : bool\n",
    "                 if True --> stem stopwords, if False --> normal\n",
    "    \n",
    "    return:\n",
    "    -------\n",
    "    text : str\n",
    "           cleaned questing string \n",
    "    \"\"\"\n",
    "    text = text.lower().split()  # split tokenize sentence into words\n",
    "\n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)  # other than the mentioned things(^) will replaced by space\n",
    "    text = re.sub(r\"what's\", \"what is \", text)  # what's replaced by what is\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    # Optionally, shorten words to their stems\n",
    "    if stem_words:\n",
    "        text = text.split()\n",
    "        stemer = SnowballStemmer('english')\n",
    "        stemmed_words = [stemmer.stem(word) for word in text]\n",
    "        text = \" \".join(stemmed_words)\n",
    "    \n",
    "    # Return a list of words\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_to_tuples(df, remove_stopwords, stem_words):\n",
    "    questions_pair = []\n",
    "    labels = []\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        q1 = text_to_wordlist(str(row['question1']), remove_stopwords, stem_words)\n",
    "        q2 = text_to_wordlist(str(row['question2']), remove_stopwords, stem_words)\n",
    "        label = int(row['is_duplicate'])\n",
    "        if q1 and q2:\n",
    "            questions_pair.append((q1, q2))\n",
    "            labels.append(label)\n",
    "\n",
    "    print ('Question Pairs: ', len(questions_pair))\n",
    "    return questions_pair, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Language:\n",
    "    def __init__(self):\n",
    "        \"\"\" \n",
    "        Language class keeps track of the datasets vocabulary and creates \n",
    "        a words to index dictionary that will be required in the pytroch dataset\n",
    "        \"\"\"\n",
    "        self.word2index = {}  # sets index accodringly to unique ness - most common lower index e.g.1 \n",
    "        self.word2count = {}  # counts each unique word \n",
    "        self.index2word = {}  # reverse of word3index\n",
    "        self.n_words = 0\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words + 1\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words + 1] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class QuoraDataset(Dataset):\n",
    "    def __init__(self, questions_list, word2index, labels):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "        -------\n",
    "        questions_list : list\n",
    "                         list with tuples of all the questions pairs \n",
    "        \n",
    "        word2index : dict\n",
    "                     vocbulary of the dataset\n",
    "        labels : list \n",
    "                 list of the corrsponding labels to the question pairs \n",
    "        \n",
    "        \"\"\"\n",
    "        self.questions_list = questions_list\n",
    "        self.labels = labels\n",
    "        self.word2index = word2index\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        questions_pair = self.questions_list[index]\n",
    "        q1 = questions_pair[0]\n",
    "        q1_indices = []\n",
    "        for word in q1.split():\n",
    "            q1_indices.append(self.word2index[word])\n",
    "            \n",
    "        q2 = questions_pair[1]\n",
    "        q2_indices = []\n",
    "        for word in q2.split():\n",
    "            q2_indices.append(self.word2index[word])\n",
    "            \n",
    "        # q1_indices and q2_indices are lists of indices against words used in the sentence \n",
    "        return {\n",
    "            'q1': q1,\n",
    "            'q2': q2,\n",
    "            'q1_token': q1_indices, \n",
    "            'q2_token': q2_indices, \n",
    "            'labels': self.labels[index], \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    q1_text_list = []\n",
    "    q2_text_list = []\n",
    "    q1_list = []\n",
    "    q2_list = []\n",
    "    labels = []\n",
    "    for item in batch:\n",
    "        q1_text_list.append(item['q1'])\n",
    "        q2_text_list.append(item['q2'])\n",
    "        q1_list.append(item['q1_token'])\n",
    "        q2_list.append(item['q2_token'])\n",
    "        labels.append(item['labels'])\n",
    "          \n",
    "        \n",
    "    q1_lengths = [len(q) for q in q1_list]\n",
    "    q2_lengths = [len(q) for q in q2_list]\n",
    "    \n",
    "    return {\n",
    "        'q1_text': q1_text_list,\n",
    "        'q2_text': q2_text_list, \n",
    "        'q1_token': q1_list, \n",
    "        'q2_token': q2_list,\n",
    "        'q1_lengths': q1_lengths, \n",
    "        'q2_lengths': q2_lengths,\n",
    "        'labels': labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pretrained weights for model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 18:59:56.210019: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 18:59:57.087481: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 18:59:57.087570: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 18:59:57.087579: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0806b364474c69a86988d74c3a2d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0860df092edf47d7959c0a9fd27f3d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406e581b53b743e59efaa2756f35bb88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f28a58980654084af4bb8aeee63faa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load BERT model and tokenizer\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_bert_embedding(word):\n",
    "    inputs = bert_tokenizer(word, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    # Take the mean of the last layer hidden states as the word embedding\n",
    "    # This is a simplification, you might want to experiment with other strategies\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "def create_pretrained_weights(embedding_dim, language):\n",
    "    \"\"\" Load pretrained weight and create pretrained weights for the embedding layer of the model from pre-trained embeddings \"\"\"\n",
    "    n_words_vocab = len(language.word2index)\n",
    "    \n",
    "    # Initialize weights tensor\n",
    "    weights = torch.randn(n_words_vocab + 1, embedding_dim)\n",
    "    weights[0] = torch.zeros(embedding_dim)\n",
    "    \n",
    "    for word, lang_word_index in language.word2index.items():\n",
    "        # Get BERT embedding for the word\n",
    "        bert_embedding = get_bert_embedding(word)\n",
    "        # Update the weights matrix\n",
    "        if bert_embedding.size(1) == embedding_dim:\n",
    "            weights[lang_word_index] = bert_embedding\n",
    "        else:\n",
    "            print(f\"Skipping {word} due to incompatible embedding dimension\")\n",
    "    \n",
    "    return weights\n",
    "\n",
    "# Define your language object and the embedding dimension\n",
    "# language = ...\n",
    "# embedding_dim = 768  # BERT-base has 768 dimensions\n",
    "\n",
    "# Now, you can create your pretrained weights matrix\n",
    "# pretrained_weights = create_pretrained_weights(embedding_dim, language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.modules import dropout\n",
    "from torch.nn.utils.rnn import pad_sequence, pad_packed_sequence, pack_padded_sequence\n",
    "import numpy as np\n",
    "\n",
    "class EmbeddingLSTMNet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_dim,\n",
    "            hidden_cells,\n",
    "            num_layers, \n",
    "            embedding_rquires_grad,\n",
    "            pretrained_weights,\n",
    "            dropout,\n",
    "            simple,\n",
    "            ):\n",
    "        super(EmbeddingLSTMNet, self).__init__()\n",
    "        \"\"\" \n",
    "        LSTM Network and embeddings from pretrained weights\n",
    "        \n",
    "            - 1 lstm is enough since weights are shared\n",
    "        embedding_dim : int\n",
    "                        embedding dimnesion\n",
    "        hidden_cells : int \n",
    "                       number of hidden cells in LSTM\n",
    "        num_layers :  int\n",
    "                      number of layers\n",
    "        embedding_requires_grad : bool\n",
    "        pretrained_weights : torch.tensor\n",
    "                             pre-trained weights tensor \n",
    "        dropout : float\n",
    "                  indicates the dropout percentage\n",
    "        simple : bool\n",
    "                 selects the simplest model, only LSTM layer\n",
    "        \"\"\"\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim, \n",
    "            hidden_size=hidden_cells, \n",
    "            num_layers=num_layers, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc1 = nn.Linear(hidden_cells, hidden_cells)\n",
    "        self.fc = nn.Linear(hidden_cells, hidden_cells)\n",
    "        self.relu = nn.ReLU()\n",
    "        # initialize embeddings \n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_weights)\n",
    "        self.embedding.weight.requires_grad = embedding_rquires_grad\n",
    "\n",
    "        # self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.device = 'cpu'\n",
    "        self.simple = simple\n",
    "\n",
    "    def forward(self, question, lengths): \n",
    "        \"\"\" \n",
    "        Params:\n",
    "        -------\n",
    "        question : (batch dim, sequence) # Question ke words ka index ek batch ka yaha 31 ka batch h\n",
    "                   i.e. [ [i1, i2, i3], -------- Q1[0]\n",
    "                          [j1, j2, j4, j5] ] --- Q1[1]\n",
    "        lenghts : list\n",
    "                  list all the lengths of each question  \n",
    "        \n",
    "        Return:\n",
    "        -------\n",
    "        result : torch.tensor\n",
    "                 output tesnor of of forward pass \n",
    "        \"\"\"\n",
    "        # Reverse the sequence lengths indices in decreasing order (pytorch requirement for pad and pack)\n",
    "        sorted_indices = np.flipud(np.argsort(lengths))\n",
    "        lengths = np.flipud(np.sort(lengths))\n",
    "        lengths = lengths.copy()\n",
    "        \n",
    "        # Reorder questions in the decreasing order of their lengths\n",
    "        ordered_questions = [torch.LongTensor(question[i]).to(self.device) for i in sorted_indices]\n",
    "        # Pad sequences with 0s to the max length sequence in the batch\n",
    "        ordered_questions = pad_sequence(ordered_questions, batch_first=True)\n",
    "        # Retrieve Embeddings\n",
    "        embeddings = self.embedding(ordered_questions).to(self.device)\n",
    "        \n",
    "        \n",
    "        # Model forward \n",
    "        embeddings = self.dropout(embeddings)\n",
    "        # Pack the padded sequences and pass it through LSTM\n",
    "        packed = pack_padded_sequence(embeddings, lengths, batch_first=True)   # Explained below\n",
    "        out, (hn, cn) = self.lstm(packed)\n",
    "        # Unpack the padded sequence and pass it through the linear layers \n",
    "        unpacked, unpacked_len = pad_packed_sequence(out, batch_first=True, total_length=int(lengths[0]))\n",
    "        \n",
    "        if self.simple == False:\n",
    "            out = self.fc1(unpacked)\n",
    "            out = self.relu(out)\n",
    "            out = self.fc(out)\n",
    "        else:\n",
    "            out = unpacked\n",
    "        \n",
    "        # Reorder the output to the original order in which the questions were passed\n",
    "        result = torch.FloatTensor(out.size())\n",
    "        for i, encoded_matrix in enumerate(out):\n",
    "            result[sorted_indices[i]] = encoded_matrix\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, embedding_lstm_net):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \"\"\"\n",
    "        Siamese LSTM Network \n",
    "\n",
    "        Params:\n",
    "        -------\n",
    "        embedding_lstm_net : nn.Module\n",
    "                             embedded LSTM Network \n",
    "        \"\"\"\n",
    "        self.embedding = embedding_lstm_net\n",
    "        \n",
    "        # self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.device = 'cpu'\n",
    "        \n",
    "    def forward(self, q1, q2, q1_lengths, q2_lengths):\n",
    "        \"\"\" Forward pass \n",
    "        Params:\n",
    "        -------\n",
    "        q1 : pad sequence tensor \n",
    "             question 1  \n",
    "        q2 : pad sequence tensor \n",
    "             question 2  \n",
    "        q1_lengths : torch.tensor\n",
    "                      original lengths of each question 1\n",
    "        q2_lengths : torch.tensor\n",
    "                      original lengths of each question 1\n",
    "        Returns:\n",
    "        --------\n",
    "        similarity_score : torch.tensor\n",
    "        \"\"\"\n",
    "        output_q1 = self.embedding(q1, q1_lengths)\n",
    "        output_q2 = self.embedding(q2, q2_lengths)\n",
    "        similarity_score = torch.zeros(output_q1.size()[0]).to(self.device)\n",
    "        # Calculate Similarity Score between both questions in a single pair\n",
    "        for index in range(output_q1.size()[0]):\n",
    "            # Sequence lenghts are being used to index and retrieve the activations before the zero padding since they were not part of original question\n",
    "            q1 = output_q1[index, q1_lengths[index] - 1, :]\n",
    "            q2 = output_q2[index, q2_lengths[index] - 1, :]\n",
    "            similarity_score[index] = self.manhattan_distance(q1, q2)\n",
    "        \n",
    "        return similarity_score\n",
    "    \n",
    "    def manhattan_distance(self, q1, q2):\n",
    "        \"\"\" Computes the Mannhatten distance between the two question tokens \"\"\"\n",
    "        return torch.exp(-torch.sum(torch.abs(q1 - q2), dim=0)).to(self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression output_q1[index, q1_lengths[index] - 1, :] is not slicing from that index to the end of the vector. Instead, it's selecting a specific row from a 3D tensor. Let's break down the expression for clarity:\n",
    "\n",
    "output_q1 is a 3D tensor, where its dimensions could be represented as [batch_size, sequence_length, embedding_dimension].\n",
    "index specifies which element in the batch we are considering.\n",
    "q1_lengths[index] - 1 specifies the index of the last non-padded word in the sequence for the index-th element in the batch. This is because q1_lengths[index] gives the length of the sequence, and subtracting 1 adjusts for 0-indexing.\n",
    ": specifies that we want all elements along the embedding dimension.\n",
    "So, output_q1[index, q1_lengths[index] - 1, :] is selecting the embedding of the last non-padded word for the index-th element in the batch. It's a vector, not a slice of vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Coroutine\n",
    "from tqdm import tqdm\n",
    "import time \n",
    "import wandb\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, model, hparams, train_dataloader, val_dataloader, \n",
    "        train_indices, val_indices, log_to_wandb, lr_scheduler_enabler=True):\n",
    "        \"\"\" \n",
    "        This Class fits the model \n",
    "\n",
    "        Params:\n",
    "        -------  \n",
    "        model : nn.Module\n",
    "                Pytorch NN Model that is spposed to be fitted/trained\n",
    "        hparams : dict\n",
    "                  Dictionary of Hyperparametes  \n",
    "        train_dataloader : torch.utils.data.DataLoader\n",
    "                           Training DataLoader\n",
    "        val_dataloader : torch.utils.data.DataLoader\n",
    "                         Validation DataLoader \n",
    "        train_indices : list \n",
    "                        list of the train indices\n",
    "        val_indices : list\n",
    "                      list of the val indices \n",
    "        lr_scheduler_enabler : bool\n",
    "                               if True enables Learning rate scheduler, if False disables it\n",
    "        \"\"\"\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.lr_scheduler_enabler = lr_scheduler_enabler\n",
    "        self.hparams = hparams \n",
    "        self.learning_rate = hparams['learning_rate']\n",
    "        self.epochs = hparams['epoch']\n",
    "        self.train_indices = train_indices\n",
    "        self.val_indices = val_indices\n",
    "        self.log_to_wandb = log_to_wandb\n",
    "\n",
    "        # self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.device = 'cpu'\n",
    "        if self.device == \"cuda\":\n",
    "            self.threshold = hparams['threshold'].to(self.device)\n",
    "        else:\n",
    "            self.threshold = hparams['threshold'].to(self.device)\n",
    "\n",
    "        self.model = model\n",
    "        self.optimizer = self.optimization()\n",
    "        self.loss_fn = self.loss()\n",
    "        self.lr_scheduler = self.learning_rate_scheduler() \n",
    "\n",
    "        self.data = dict()\n",
    "        self.data[\"train_loss\"] = list()\n",
    "        self.data[\"train_acc\"] = list()\n",
    "        self.data[\"val_loss\"] = list()\n",
    "        self.data[\"val_acc\"] = list()\n",
    "\n",
    "        if self.log_to_wandb:\n",
    "            self.init_wandb()\n",
    "\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\" Trains an epoch \"\"\"\n",
    "        self.model.train()\n",
    "\n",
    "        loss_history = []\n",
    "        correct_total = 0\n",
    "        with tqdm(self.train_dataloader, unit=\"batch\") as tepoch:\n",
    "            for i, batch in enumerate(tepoch):\n",
    "                tepoch.set_description(f\"Epoch [{epoch+1}/{self.epochs}]  Training\")\n",
    "                if self.device == \"cuda\":\n",
    "                    q1, q2 = batch['q1_token'].to(self.device), batch['q2_token'].to(self.device)\n",
    "                    q1_len, q2_len = batch['q1_lengths'].to(self.device), batch['q2_lengths'].to(self.device)\n",
    "                    y = torch.FloatTensor(batch['labels']).to(self.device)\n",
    "                else:\n",
    "                    q1, q2 = batch['q1_token'], batch['q2_token']\n",
    "                    q1_len, q2_len = batch['q1_lengths'], batch['q2_lengths']\n",
    "                    y = torch.FloatTensor(batch['labels'])\n",
    "                \n",
    "                # Reset the gardients \n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Model forward and predictions\n",
    "                similarity = self.model(q1, q2, q1_len, q2_len)\n",
    "                y_pred = (similarity > self.threshold).float() * 1\n",
    "                correct = self.inferece(y_pred, y)\n",
    "                correct_total += correct\n",
    "\n",
    "                # Calculate the loss \n",
    "                loss = self.loss_fn(similarity, y)\n",
    "                loss_history.append(loss.item())\n",
    "\n",
    "                # Calculate gradients by performign the backward pass\n",
    "                loss.backward()\n",
    "                \n",
    "                # Update weights\n",
    "                self.optimizer.step()\n",
    "\n",
    "                if i % 100 == 0:\n",
    "                    tepoch.set_postfix(train_loss=np.mean(loss_history), train_acc=f'{(correct/y.size()[0])*100} %' )\n",
    "            \n",
    "            # Enable learning rate scheduler  \n",
    "            if self.lr_scheduler_enabler:\n",
    "                self.lr_scheduler.step()\n",
    "\n",
    "        return  np.mean(loss_history), (correct_total/len(self.train_indices))*100\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\" Validates an epoch \"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        loss_history = []\n",
    "        correct_total = 0\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(self.val_dataloader):\n",
    "                if self.device == \"cuda\":\n",
    "                    q1, q2 = batch['q1_token'].to(self.device), batch['q2_token'].to(self.device)\n",
    "                    q1_len, q2_len = batch['q1_lengths'].to(self.device), batch['q2_lengths'].to(self.device)\n",
    "                    y = torch.FloatTensor(batch['labels']).to(self.device)\n",
    "                else:\n",
    "                    q1, q2 = batch['q1_token'], batch['q2_token']\n",
    "                    q1_len, q2_len = batch['q1_lengths'], batch['q2_lengths']\n",
    "                    y = torch.FloatTensor(batch['labels'])\n",
    "\n",
    "                # Model forward and predictions\n",
    "                similarity = self.model(q1, q2, q1_len, q2_len)\n",
    "                y_pred = (similarity > self.threshold).float() * 1\n",
    "                correct = self.inferece(y_pred, y)\n",
    "                correct_total += correct\n",
    "\n",
    "                # Calculate the loss \n",
    "                loss = self.loss_fn(similarity, y)\n",
    "                loss_history.append(loss.item())\n",
    "\n",
    "        avg_val_acc =  correct_total/len(self.val_indices) * 100 \n",
    "        return np.mean(loss_history), avg_val_acc\n",
    "    \n",
    "    def inferece(self, y_pred, y):\n",
    "        \"\"\" Performs inference \"\"\"\n",
    "        return (y_pred == y).sum().item()\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\" Fits the model \"\"\"\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        for e in range(self.epochs):\n",
    "            train_loss, train_acc = self.train_epoch(e)\n",
    "            val_loss, val_acc = self.evaluate()\n",
    "            print(f'Epoch [{e+1}/{self.epochs}] Validation: val_loss: {val_loss} val_acc: {val_acc} %')\n",
    "            \n",
    "            self.data[\"train_loss\"].append(train_loss)\n",
    "            self.data[\"train_acc\"].append(train_acc)\n",
    "            self.data[\"val_loss\"].append(val_loss)\n",
    "            self.data[\"val_acc\"].append(val_acc)\n",
    "\n",
    "            if self.log_to_wandb:\n",
    "                self.log_metrics_to_wandb(train_loss, train_acc, val_loss, val_acc)\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        if self.log_to_wandb:\n",
    "            wandb.finish()\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\" Tests the model \"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        predictions = []\n",
    "        labels_list = []\n",
    "        loss_history = []\n",
    "        correct_total = 0\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(self.val_dataloader):\n",
    "                if self.device == \"cuda\":\n",
    "                    q1, q2 = batch['q1_token'].to(self.device), batch['q2_token'].to(self.device)\n",
    "                    q1_len, q2_len = batch['q1_lengths'].to(self.device), batch['q2_lengths'].to(self.device)\n",
    "                    y = torch.FloatTensor(batch['labels']).to(self.device)\n",
    "                else:\n",
    "                    q1, q2 = batch['q1_token'], batch['q2_token']\n",
    "                    q1_len, q2_len = batch['q1_lengths'], batch['q2_lengths']\n",
    "                    y = torch.FloatTensor(batch['labels'])\n",
    "\n",
    "                # Model forward and predictions\n",
    "                similarity = self.model(q1, q2, q1_len, q2_len)\n",
    "                y_pred = (similarity > self.threshold).float() * 1\n",
    "                predictions.append(y_pred), labels_list.append(y)\n",
    "                correct = self.inferece(y_pred, y)\n",
    "                correct_total += correct\n",
    "\n",
    "                # Calculate the loss \n",
    "                loss = self.loss_fn(similarity, y)\n",
    "                loss_history.append(loss.item())\n",
    "        \n",
    "        # Calculate the accuracy\n",
    "        avg_val_acc =  correct_total/len(self.val_indices) * 100 \n",
    "        print('- - - Model Performance - - -')\n",
    "        print(f'\\nModel Accuracy:  {avg_val_acc}')\n",
    "        print(f'Correct predictions: {correct_total}, Incorret predictions: {len(self.val_indices) - correct_total}')\n",
    "        print('')\n",
    "        cm = plotConfusionMatrix(np.hstack(predictions), np.hstack(labels_list),['similar', 'dissimilar'], title=\"Confusion Matrix Plot of Test Set\")\n",
    "        print(f'TP: {cm[0,0]}')\n",
    "        print(f'FP: {cm[1,0]}')\n",
    "        print(f'FN: {cm[0,1]}')\n",
    "        print(f'TN: {cm[1,1]}')\n",
    "        print(f'\\nPrecision Score: {precision_score(np.hstack(predictions), np.hstack(labels_list))}')\n",
    "        print(f'Recall Score: {recall_score(np.hstack(predictions), np.hstack(labels_list))}')\n",
    "        print(f'F1 Score: {f1_score(np.hstack(predictions), np.hstack(labels_list))}')\n",
    "\n",
    "        # adopted from https://www.codegrepper.com/code-examples/python/roc+curve+pytorch\n",
    "        fpr, tpr, threshold = roc_curve(np.hstack(predictions), np.hstack(labels_list))\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.title('Receiver Operating Characteristic (ROC)')\n",
    "        plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "        plt.legend(loc = 'lower right')\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1])\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        # adopted from https://www.codegrepper.com/code-examples/python/roc+curve+pytorch\n",
    "\n",
    "    def predict(self, test_sample_dict):\n",
    "        \"\"\" Uses the model to predict the similarity of a given input pair of questions\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        print('question 1:', test_sample_dict['q1_text'])\n",
    "        print('question 2:', test_sample_dict['q2_text'])\n",
    "        print('tokens  q1:', test_sample_dict['q1_token'])\n",
    "        print('tokens  q2:', test_sample_dict['q2_token'])\n",
    "\n",
    "        q1, q2 = test_sample_dict['q1_token'], test_sample_dict['q2_token']\n",
    "        q1_len, q2_len = test_sample_dict['q1_lengths'], test_sample_dict['q2_lengths']\n",
    "        y = torch.FloatTensor(test_sample_dict['labels'])\n",
    "        \n",
    "        # Model forward and predictions\n",
    "        similarity = self.model(q1, q2, q1_len, q2_len)\n",
    "        y_pred = (similarity > self.threshold).float() * 1\n",
    "        \n",
    "        print(f'\\n\\nModel predicts {y_pred.item()} --> Actual value {y.item()}')\n",
    "        if y_pred.item() == y.item():\n",
    "            print(f'Model prediction is correct :)')\n",
    "\n",
    "            if y_pred.item() == 1.0:\n",
    "                print(f'\\nThe questions {test_sample_dict[\"q1_text\"]} and {test_sample_dict[\"q2_text\"]} are similar!')\n",
    "            else:\n",
    "                print(f'\\nThe questions {test_sample_dict[\"q1_text\"]} and {test_sample_dict[\"q2_text\"]} are dissimilar!')    \n",
    "        else:\n",
    "            print(f'Model prediction is inaccurate :(')\n",
    "            if y_pred.item() == 1.0:\n",
    "                print(f'\\nThe questions {test_sample_dict[\"q1_text\"]} and {test_sample_dict[\"q2_text\"]} should be dissimilar!')\n",
    "            else:\n",
    "                print(f'\\nThe questions {test_sample_dict[\"q1_text\"]} and {test_sample_dict[\"q2_text\"]} should be similar!')  \n",
    "        \n",
    "    def optimization(self):\n",
    "        \"\"\" Initializes the optimizer \"\"\"\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "    \n",
    "    def learning_rate_scheduler(self):\n",
    "        \"\"\" Initializes the learning rate scheduler \"\"\"\n",
    "        return torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.9)\n",
    "\n",
    "    def loss(self):\n",
    "        \"\"\" Initializes the loss \"\"\"\n",
    "        return nn.MSELoss() #nn.CrossEntropyLoss()\n",
    "    \n",
    "    def return_data(self):\n",
    "        \"\"\" Output the data \"\"\"\n",
    "        return self.data\n",
    "\n",
    "    def init_wandb(self):\n",
    "        \"\"\" init weight & biases \"\"\"\n",
    "        # capture hyperparameters\n",
    "        config = self.hparams\n",
    "        # initialize wandb\n",
    "        wandb.init(project=\"Siamese_LSTM\", entity=\"maxifor\", config=config)\n",
    "\n",
    "    def log_metrics_to_wandb(self, train_loss, train_acc, val_loss, val_acc):\n",
    "        \"\"\" log metric to weights and biases \"\"\"\n",
    "        wandb.log({\"train_loss\": train_loss,})\n",
    "        wandb.log({\"train_acc\": train_acc,})\n",
    "        wandb.log({\"val_loss\": val_loss,})\n",
    "        wandb.log({\"val_acc\": val_acc,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    \"\"\" Saves a pytorch model locally \"\"\"\n",
    "    return torch.save(model.state_dict(), path)\n",
    "\n",
    "def load_model(model, path):\n",
    "    \"\"\" Loads a model locally \"\"\"\n",
    "    m = model(n_classes=10)\n",
    "    # load the state dict and pass it to the load_state_dict function\n",
    "    return m.load_state_dict(torch.load(\"./model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def plotConfusionMatrix(y, y_pred, classes, title=None):\n",
    "    \"\"\" Plots a confusion matrix \"\"\"\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    ax = sns.heatmap(cm, xticklabels=classes, yticklabels=classes, annot=True, fmt='0.2g', cmap=plt.cm.Blues)\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    ax.set_xlabel('Predictions')\n",
    "    ax.set_ylabel('Test Set')\n",
    "    plt.show()\n",
    "\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Global Varibles and Paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root and directory paths \n",
    "ROOT_PATH = os.getcwd()\n",
    "DATA_FOLDER_PATH = ROOT_PATH + '/data'\n",
    "MODEL_FOLDER_PATH = ROOT_PATH \n",
    "# important paths \n",
    "DATASET_FILE_PATH = DATA_FOLDER_PATH + '/mini_quora_dataset_30_50_50k.csv'\n",
    "\n",
    "# general variables\n",
    "EMBEDDING_REQUIRES_GRAD = False\n",
    "NUM_LAYERS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters - adjust them to optimize model perfromance\n",
    "\n",
    "hparams = {\n",
    "    'threshold':        torch.Tensor([0.5]),  # Threshold for determining similarity\n",
    "    'learning_rate':    1e-03,                # Learning rate\n",
    "    'epoch':            20,                   # Number of epochs\n",
    "    'batch_size':       32,                   # Batch size\n",
    "    'hidden_dim':       100,                  # Number of hidden dimensions\n",
    "    'embedding_dim':    768,                  # Number of embedding dimensions\n",
    "    'dropout':          0.0,                  # Dropout\n",
    "    'remove_stopwords': False,                # Removes stopwords\n",
    "    'stem_words':       False,                # Remove stem words\n",
    "    'simple':           True,                 # Chooses simple or more complex model\n",
    "    'log_to_wandb':     False,                # Chooses to log to wandb or not\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Dataset\n",
    "\n",
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select question pair and labels and prepare the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>max_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307549</td>\n",
       "      <td>603786</td>\n",
       "      <td>603787</td>\n",
       "      <td>What are some different ways to make money fast?</td>\n",
       "      <td>What are fast ways to make money?</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221916</td>\n",
       "      <td>437426</td>\n",
       "      <td>437427</td>\n",
       "      <td>How can I continue to improve my English?</td>\n",
       "      <td>How can I understand english?</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>177830</td>\n",
       "      <td>351280</td>\n",
       "      <td>351281</td>\n",
       "      <td>How do I promote my youtube videos?</td>\n",
       "      <td>What is the best way to promote YouTube videos?</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128018</td>\n",
       "      <td>253605</td>\n",
       "      <td>253606</td>\n",
       "      <td>How can I organize a Quora Meetup in Pune?</td>\n",
       "      <td>Is there a Pune Quora Meetup group?</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>177761</td>\n",
       "      <td>351144</td>\n",
       "      <td>351145</td>\n",
       "      <td>What is the most badass moment of Game of Thro...</td>\n",
       "      <td>Who will die in season 5 of Game of Thrones?</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>95213</td>\n",
       "      <td>189005</td>\n",
       "      <td>189006</td>\n",
       "      <td>How does drop shipping work exactly?</td>\n",
       "      <td>What is drop shipping and how does it work?</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>62682</td>\n",
       "      <td>124658</td>\n",
       "      <td>124659</td>\n",
       "      <td>What are the best movies to watch in Hollywood?</td>\n",
       "      <td>Which are the best Hollywood movies of all time?</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>109939</td>\n",
       "      <td>218008</td>\n",
       "      <td>218009</td>\n",
       "      <td>Am I a sociopath, schizoid, or neither?</td>\n",
       "      <td>Am I a sociopath?</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>370854</td>\n",
       "      <td>725712</td>\n",
       "      <td>725713</td>\n",
       "      <td>What is your marketing strategy?</td>\n",
       "      <td>What is a market strategy?</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>268327</td>\n",
       "      <td>527813</td>\n",
       "      <td>527814</td>\n",
       "      <td>What will be the qualifying marks for neet 2016?</td>\n",
       "      <td>What might be the qualifing mark in neet 2016?</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    qid1    qid2  \\\n",
       "0      307549  603786  603787   \n",
       "1      221916  437426  437427   \n",
       "2      177830  351280  351281   \n",
       "3      128018  253605  253606   \n",
       "4      177761  351144  351145   \n",
       "...       ...     ...     ...   \n",
       "49995   95213  189005  189006   \n",
       "49996   62682  124658  124659   \n",
       "49997  109939  218008  218009   \n",
       "49998  370854  725712  725713   \n",
       "49999  268327  527813  527814   \n",
       "\n",
       "                                               question1  \\\n",
       "0       What are some different ways to make money fast?   \n",
       "1              How can I continue to improve my English?   \n",
       "2                    How do I promote my youtube videos?   \n",
       "3             How can I organize a Quora Meetup in Pune?   \n",
       "4      What is the most badass moment of Game of Thro...   \n",
       "...                                                  ...   \n",
       "49995               How does drop shipping work exactly?   \n",
       "49996    What are the best movies to watch in Hollywood?   \n",
       "49997            Am I a sociopath, schizoid, or neither?   \n",
       "49998                   What is your marketing strategy?   \n",
       "49999   What will be the qualifying marks for neet 2016?   \n",
       "\n",
       "                                              question2  is_duplicate  \\\n",
       "0                     What are fast ways to make money?             1   \n",
       "1                         How can I understand english?             1   \n",
       "2       What is the best way to promote YouTube videos?             1   \n",
       "3                   Is there a Pune Quora Meetup group?             0   \n",
       "4          Who will die in season 5 of Game of Thrones?             0   \n",
       "...                                                 ...           ...   \n",
       "49995       What is drop shipping and how does it work?             1   \n",
       "49996  Which are the best Hollywood movies of all time?             1   \n",
       "49997                                 Am I a sociopath?             0   \n",
       "49998                        What is a market strategy?             0   \n",
       "49999    What might be the qualifing mark in neet 2016?             1   \n",
       "\n",
       "       max_length  \n",
       "0              48  \n",
       "1              41  \n",
       "2              47  \n",
       "3              42  \n",
       "4              50  \n",
       "...           ...  \n",
       "49995          43  \n",
       "49996          48  \n",
       "49997          39  \n",
       "49998          32  \n",
       "49999          48  \n",
       "\n",
       "[50000 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Pairs:  49999\n"
     ]
    }
   ],
   "source": [
    "q_pair, labels = convert_data_to_tuples(df, hparams['remove_stopwords'], hparams['stem_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(q_pair[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = Language()\n",
    "for data in [q_pair]:\n",
    "    for question_pair in data:\n",
    "        q1 = question_pair[0]\n",
    "        q2 = question_pair[1]\n",
    "        language.addSentence(q1)\n",
    "        language.addSentence(q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# language.word2index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary size = 23019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q1': 'what are some different ways to make money fast',\n",
       " 'q2': 'what are fast ways to make money',\n",
       " 'q1_token': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'q2_token': [1, 2, 9, 5, 6, 7, 8],\n",
       " 'labels': 1}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora_dataset = QuoraDataset(q_pair, language.word2index, labels)\n",
    "quora_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question 1: what are some different ways to make money fast\n",
      "question 2: what are fast ways to make money\n",
      "tokens  q1: [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "tokens  q2: [1, 2, 9, 5, 6, 7, 8]\n",
      "labels    : 1\n"
     ]
    }
   ],
   "source": [
    "# example output\n",
    "\n",
    "for sample in quora_dataset:\n",
    "    print('question 1:', sample['q1'])\n",
    "    print('question 2:', sample['q2'])\n",
    "    print('tokens  q1:', sample['q1_token'])\n",
    "    print('tokens  q2:', sample['q2_token'])\n",
    "    print('labels    :', sample['labels'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size 39999, Validation Set Size 10000,\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "train_split = 0.8\n",
    "val_split = 0.2\n",
    "\n",
    "dataset_size = len(quora_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "\n",
    "split_train = int(train_split*dataset_size)\n",
    "\n",
    "shuffle_dataset = True\n",
    "random_seed = 46\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[:split_train], indices[split_train:]\n",
    "\n",
    "assert len(train_indices) + len(val_indices) == dataset_size\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_dataloader = DataLoader(quora_dataset, batch_size=hparams['batch_size'], sampler=train_sampler, collate_fn=collate)\n",
    "val_dataloader = DataLoader(quora_dataset, batch_size=hparams['batch_size'], sampler=val_sampler, collate_fn=collate)\n",
    "\n",
    "print('Training Set Size {}, Validation Set Size {},'.format(len(train_indices), len(val_indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams['embedding_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.1453, -0.1184, -0.3657,  ...,  0.2657,  0.0440, -0.1574],\n",
       "        [ 0.0460, -0.0847, -0.0883,  ...,  0.0237,  0.0504,  0.0119],\n",
       "        ...,\n",
       "        [ 0.0384,  0.0385, -0.1748,  ...,  0.0525, -0.3806, -0.0064],\n",
       "        [-0.0929, -0.0494, -0.1863,  ..., -0.1793, -0.3840,  0.2119],\n",
       "        [ 0.0892, -0.3455, -0.0586,  ..., -0.0083, -0.3407,  0.4691]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create pretrained weights \n",
    "# instead import the pretrained_weights.pt \n",
    "# pretrained_weights = create_pretrained_weights(hparams['embedding_dim'], language)\n",
    "# pretrained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save the tensor to a file\n",
    "# torch.save(pretrained_weights, 'pretrained_weights_bert.pt')\n",
    "\n",
    "# To load the tensor back from the file\n",
    "pretrained_weights = torch.load('pretrained_weights_bert.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23020, 768])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pretrained_weights = torch.load('pretrained_weights.pt')\n",
    "pretrained_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding net\n",
    "embedding_net = EmbeddingLSTMNet(\n",
    "    hparams['embedding_dim'],\n",
    "    hparams['hidden_dim'],\n",
    "    NUM_LAYERS,\n",
    "    EMBEDDING_REQUIRES_GRAD,\n",
    "    pretrained_weights,\n",
    "    hparams['dropout'],\n",
    "    hparams['simple'], # if simple=True --> simple model, if simple=False --> more complex model (2 linear layers plus relu)\n",
    ")\n",
    "\n",
    "# siamese model\n",
    "model = SiameseNetwork(embedding_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.2303e-01, 8.7905e-06, 6.1107e-02, 3.3307e-04, 2.4695e-01, 1.5025e-04,\n",
       "        1.0059e-03, 1.4672e-01, 2.2007e-03, 6.1370e-03, 2.8082e-03, 9.3672e-04,\n",
       "        2.0973e-01, 2.1819e-01, 1.6127e-03, 1.8007e-01, 2.2493e-01, 2.9324e-01,\n",
       "        1.1463e-01, 7.4534e-02, 6.5871e-01, 1.0120e-01, 8.7416e-03, 4.7258e-01,\n",
       "        2.2081e-01, 2.2206e-01, 5.9415e-01, 5.1976e-03, 3.2625e-04, 6.1427e-01,\n",
       "        2.0490e-03], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model class with one batch from the dataloader \n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    q1, q2 = batch['q1_token'], batch['q2_token']\n",
    "    q1_len, q2_len = batch['q1_lengths'], batch['q2_lengths']\n",
    "    y = torch.FloatTensor(batch['labels'])\n",
    "\n",
    "model(q1, q2, q1_len, q2_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiameseNetwork(\n",
       "  (embedding): EmbeddingLSTMNet(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (lstm): LSTM(768, 100, batch_first=True)\n",
       "    (fc1): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (fc): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (embedding): Embedding(23020, 768)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.6388e-01, 1.5326e-01, 3.6053e-03, 3.4150e-04, 1.7748e-04, 4.8024e-01,\n",
       "        3.9379e-03, 1.9377e-04, 5.3632e-02, 2.1508e-03, 1.0332e-01, 2.5281e-02,\n",
       "        3.3412e-02, 1.4845e-01, 1.1722e-03, 8.8196e-04, 4.0894e-03, 1.3888e-02,\n",
       "        4.6348e-01, 1.2159e-01, 1.0485e-03, 4.4244e-05, 2.4312e-01, 1.2415e-03,\n",
       "        2.3348e-03, 1.0000e+00, 1.7922e-01, 9.4087e-02, 3.8326e-03, 6.6015e-02,\n",
       "        1.2347e-01], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model class with one batch from the dataloader \n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    q1, q2 = batch['q1_token'], batch['q2_token']\n",
    "    q1_len, q2_len = batch['q1_lengths'], batch['q2_lengths']\n",
    "    y = torch.FloatTensor(batch['labels'])\n",
    "\n",
    "model(q1, q2, q1_len, q2_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ModelTrainer(\n",
    "    model, \n",
    "    hparams, \n",
    "    train_dataloader, \n",
    "    val_dataloader,\n",
    "    train_indices, \n",
    "    val_indices,\n",
    "    log_to_wandb=hparams['log_to_wandb'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]  Training: 100%|██████████| 1250/1250 [00:27<00:00, 45.16batch/s, train_acc=68.75 %, train_loss=0.199] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] Validation: val_loss: 0.185863901179629 val_acc: 71.83 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/20]  Training: 100%|██████████| 1250/1250 [00:27<00:00, 44.79batch/s, train_acc=78.125 %, train_loss=0.176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] Validation: val_loss: 0.17565705324895084 val_acc: 73.68 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/20]  Training: 100%|██████████| 1250/1250 [00:27<00:00, 45.47batch/s, train_acc=68.75 %, train_loss=0.167] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] Validation: val_loss: 0.17551806121588515 val_acc: 73.53 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/20]  Training: 100%|██████████| 1250/1250 [00:27<00:00, 45.41batch/s, train_acc=75.0 %, train_loss=0.16]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] Validation: val_loss: 0.16816117197941668 val_acc: 75.36 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/20]  Training: 100%|██████████| 1250/1250 [00:27<00:00, 45.14batch/s, train_acc=68.75 %, train_loss=0.155] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] Validation: val_loss: 0.16570999444768833 val_acc: 75.9 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/20]  Training: 100%|██████████| 1250/1250 [00:27<00:00, 45.03batch/s, train_acc=65.625 %, train_loss=0.149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] Validation: val_loss: 0.16644532423906813 val_acc: 75.5 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/20]  Training: 100%|██████████| 1250/1250 [00:27<00:00, 44.96batch/s, train_acc=71.875 %, train_loss=0.146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] Validation: val_loss: 0.1625711434898666 val_acc: 76.25999999999999 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/20]  Training: 100%|██████████| 1250/1250 [00:27<00:00, 44.88batch/s, train_acc=65.625 %, train_loss=0.143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] Validation: val_loss: 0.16186701539701548 val_acc: 76.66 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/20]  Training: 100%|██████████| 1250/1250 [00:27<00:00, 45.58batch/s, train_acc=90.625 %, train_loss=0.14] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] Validation: val_loss: 0.16017889352842643 val_acc: 76.9 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/20]  Training: 100%|██████████| 1250/1250 [00:27<00:00, 45.41batch/s, train_acc=87.5 %, train_loss=0.137]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] Validation: val_loss: 0.160514130212438 val_acc: 76.8 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/20]  Training: 100%|██████████| 1250/1250 [00:28<00:00, 43.49batch/s, train_acc=78.125 %, train_loss=0.135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] Validation: val_loss: 0.15866721364351127 val_acc: 77.18 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/20]  Training: 100%|██████████| 1250/1250 [00:28<00:00, 43.70batch/s, train_acc=87.5 %, train_loss=0.133]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] Validation: val_loss: 0.1580710782886694 val_acc: 77.17 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/20]  Training: 100%|██████████| 1250/1250 [00:28<00:00, 43.37batch/s, train_acc=75.0 %, train_loss=0.131]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] Validation: val_loss: 0.1572305543687397 val_acc: 77.25 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/20]  Training: 100%|██████████| 1250/1250 [00:28<00:00, 43.63batch/s, train_acc=93.75 %, train_loss=0.129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] Validation: val_loss: 0.1573125218954711 val_acc: 77.3 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/20]  Training: 100%|██████████| 1250/1250 [00:28<00:00, 43.66batch/s, train_acc=87.5 %, train_loss=0.128] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] Validation: val_loss: 0.15726416991255915 val_acc: 77.34 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/20]  Training: 100%|██████████| 1250/1250 [00:27<00:00, 44.75batch/s, train_acc=78.125 %, train_loss=0.126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] Validation: val_loss: 0.1571494014546894 val_acc: 77.24 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/20]  Training: 100%|██████████| 1250/1250 [00:28<00:00, 43.25batch/s, train_acc=90.625 %, train_loss=0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] Validation: val_loss: 0.15641073413645498 val_acc: 77.4 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/20]  Training: 100%|██████████| 1250/1250 [00:28<00:00, 44.20batch/s, train_acc=90.625 %, train_loss=0.123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] Validation: val_loss: 0.15623907125986422 val_acc: 77.44 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/20]  Training: 100%|██████████| 1250/1250 [00:28<00:00, 44.03batch/s, train_acc=90.625 %, train_loss=0.123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] Validation: val_loss: 0.15623899987235237 val_acc: 77.51 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/20]  Training: 100%|██████████| 1250/1250 [00:29<00:00, 42.88batch/s, train_acc=75.0 %, train_loss=0.122]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] Validation: val_loss: 0.1557679654072268 val_acc: 77.4 %\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - Model Performance - - -\n",
      "\n",
      "Model Accuracy:  77.4\n",
      "Correct predictions: 7740, Incorret predictions: 2260\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 4138\n",
      "FP: 978\n",
      "FN: 1282\n",
      "TN: 3602\n",
      "\n",
      "Precision Score: 0.7375102375102375\n",
      "Recall Score: 0.7864628820960698\n",
      "F1 Score: 0.7612003381234149\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you like to store the model, uncomment the following lines and enter filename and path \n",
    "#filename = \"model.pt\"\n",
    "#path = ROOT_PATH\n",
    "#save_model(model, path + \"/\" + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predicitions\n",
    "\n",
    "Use you the previously trained model to make prediction on some samples. At the end one can input a custom question pair and see how the model is performing on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkout random sample from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question 1: ['what are some really good novels']\n",
      "question 2: ['which are some good novels']\n",
      "tokens  q1: [[1, 2, 3, 169, 155, 4326]]\n",
      "tokens  q2: [[126, 2, 3, 155, 4326]]\n",
      "\n",
      "\n",
      "Model predicts 1.0 --> Actual value 1.0\n",
      "Model prediction is correct :)\n",
      "\n",
      "The questions ['what are some really good novels'] and ['which are some good novels'] are similar!\n"
     ]
    }
   ],
   "source": [
    "ind = 10\n",
    "test_sample_train = dict()\n",
    "for idx, batch in enumerate(train_dataloader):\n",
    "    if idx == ind:\n",
    "        test_sample_train['q1_text'] = [batch['q1_text'][0]]\n",
    "        test_sample_train['q2_text'] = [batch['q2_text'][0]]\n",
    "        test_sample_train['q1_token'] = [batch['q1_token'][0]]\n",
    "        test_sample_train['q2_token'] = [batch['q2_token'][0]]\n",
    "        test_sample_train['q1_lengths'] = [batch['q1_lengths'][0]]\n",
    "        test_sample_train['q2_lengths'] = [batch['q2_lengths'][0]]\n",
    "        test_sample_train['labels'] = [batch['labels'][0]]\n",
    "\n",
    "trainer.predict(test_sample_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkout random sample from validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question 1: ['how do i get more views on my youtube videos']\n",
      "question 2: ['how do i get more traffic to my youtube videos']\n",
      "tokens  q1: [[10, 18, 12, 139, 342, 869, 83, 15, 20, 21]]\n",
      "tokens  q2: [[10, 18, 12, 139, 342, 1771, 6, 15, 20, 21]]\n",
      "\n",
      "\n",
      "Model predicts 1.0 --> Actual value 1.0\n",
      "Model prediction is correct :)\n",
      "\n",
      "The questions ['how do i get more views on my youtube videos'] and ['how do i get more traffic to my youtube videos'] are similar!\n"
     ]
    }
   ],
   "source": [
    "ind = np.random.choice(len(val_dataloader))\n",
    "\n",
    "test_sample_val = dict()\n",
    "for idx, batch in enumerate(val_dataloader):\n",
    "    if idx == ind:\n",
    "        test_sample_val['q1_text'] = [batch['q1_text'][0]]\n",
    "        test_sample_val['q2_text'] = [batch['q2_text'][0]]\n",
    "        test_sample_val['q1_token'] = [batch['q1_token'][0]]\n",
    "        test_sample_val['q2_token'] = [batch['q2_token'][0]]\n",
    "        test_sample_val['q1_lengths'] = [batch['q1_lengths'][0]]\n",
    "        test_sample_val['q2_lengths'] = [batch['q2_lengths'][0]]\n",
    "        test_sample_val['labels'] = [batch['labels'][0]]\n",
    "\n",
    "trainer.predict(test_sample_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict from custom input questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "default = True  # set to False to create your own inputs\n",
    "similar = False  # select False to dispaly dissimlar example\n",
    "\n",
    "if default:\n",
    "    if similar:\n",
    "        q1 = ['Is it cold today?']\n",
    "        q2 = ['Will it be cold today?']\n",
    "        label = [1.0]\n",
    "    else:\n",
    "        q1 = ['Will I pass the final?']\n",
    "        q2 = ['What will I have for dinner tonight?']\n",
    "        label = [0.0]\n",
    "else:\n",
    "    q1 = input(r'Enter your 1^st question: ')\n",
    "    q2 = input(r'Enter your 2^nd question: ')\n",
    "    label = input('label: ') # 0 for dissimilar, 1 for similar \n",
    "    q1 = [q1]\n",
    "    q2 = [q2]\n",
    "    label = [label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Pairs:  1\n",
      "[('will i pass the final', 'what will i have for dinner tonight')]\n",
      "question 1: ['will i pass the final']\n",
      "question 2: ['what will i have for dinner tonight']\n",
      "tokens  q1: [[41, 12, 1487, 23, 1303]]\n",
      "tokens  q2: [[1, 41, 12, 165, 63, 4425, 11626]]\n",
      "\n",
      "\n",
      "Model predicts 0.0 --> Actual value 0.0\n",
      "Model prediction is correct :)\n",
      "\n",
      "The questions ['will i pass the final'] and ['what will i have for dinner tonight'] are dissimilar!\n"
     ]
    }
   ],
   "source": [
    "# prepair custom input\n",
    "# create df\n",
    "df_own = pd.DataFrame(list(zip(q1, q2, label)), columns=['question1', 'question2', 'is_duplicate'])\n",
    "# prepare data \n",
    "q_pair_own, label = convert_data_to_tuples(df_own, hparams['remove_stopwords'], hparams['stem_words'])\n",
    "print(q_pair_own)\n",
    "\n",
    "# create dataset \n",
    "own_dataset = QuoraDataset(q_pair_own, language.word2index, label)\n",
    "\n",
    "# create dataloader\n",
    "predict_dataloader = torch.utils.data.DataLoader(own_dataset, batch_size=1, collate_fn=collate)\n",
    "\n",
    "for sample in predict_dataloader:\n",
    "    test_sample = sample\n",
    "\n",
    "# predict \n",
    "trainer.predict(test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/mustafa/nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/mustafa/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'quick', 'brown', 'foxes', 'are', 'jumping', 'over', 'the', 'lazy', 'dogs']\n",
      "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('foxes', 'NNS'), ('are', 'VBP'), ('jumping', 'VBG'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dogs', 'NNS')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - '/home/mustafa/nltk_data'\n    - '/home/mustafa/anaconda3/nltk_data'\n    - '/home/mustafa/anaconda3/share/nltk_data'\n    - '/home/mustafa/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4.zip/omw-1.4/\u001b[0m\n\n  Searched in:\n    - '/home/mustafa/nltk_data'\n    - '/home/mustafa/anaconda3/nltk_data'\n    - '/home/mustafa/anaconda3/share/nltk_data'\n    - '/home/mustafa/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_465105/3571275518.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The quick brown foxes are jumping over the lazy dogs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mlemmatized_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlemmatize_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatized_sentence\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Output: \"The quick brown fox be jump over the lazy dog\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_465105/3571275518.py\u001b[0m in \u001b[0;36mlemmatize_sentence\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Lemmatize the words with their POS tagging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mlemmatized_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_wordnet_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_tag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_tags\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatized_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Join the lemmatized words back into a sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_465105/3571275518.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Lemmatize the words with their POS tagging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mlemmatized_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_wordnet_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_tag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_tags\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatized_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Join the lemmatized words back into a sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_465105/3571275518.py\u001b[0m in \u001b[0;36mget_wordnet_pos\u001b[0;34m(treebank_tag)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mADV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOUN\u001b[0m  \u001b[0;31m# Default to noun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlemmatize_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__reader_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# This is where the magic happens!  Transform ourselves into\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, omw_reader)\u001b[0m\n\u001b[1;32m   1174\u001b[0m             )\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprovenances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0momw_prov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# A cache to store the wordnet data of multiple languages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36momw_prov\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0mprovdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0mprovdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eng\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_omw_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfileid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0mprov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlangfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - '/home/mustafa/nltk_data'\n    - '/home/mustafa/anaconda3/nltk_data'\n    - '/home/mustafa/anaconda3/share/nltk_data'\n    - '/home/mustafa/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Download wordnet data if it's your first time using NLTK lemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    # Convert the POS tagging output of NLTK to a format that the WordNetLemmatizer can understand\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # Default to noun\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    # Tokenize the sentence into words\n",
    "#     words = nltk.word_tokenize(sentence)\n",
    "    words = sentence.split()  # This both are same\n",
    "    print(words)\n",
    "    # Get the POS tagging of the words\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    print(pos_tags)\n",
    "    # Lemmatize the words with their POS tagging\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(pos_tag)) for word, pos_tag in pos_tags]\n",
    "    print(lemmatized_words)\n",
    "    # Join the lemmatized words back into a sentence\n",
    "    lemmatized_sentence = ' '.join(lemmatized_words)\n",
    "    return lemmatized_sentence\n",
    "\n",
    "# Example usage\n",
    "sentence = \"The quick brown foxes are jumping over the lazy dogs\"\n",
    "lemmatized_sentence = lemmatize_sentence(sentence)\n",
    "print(lemmatized_sentence)  # Output: \"The quick brown fox be jump over the lazy dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'mustafa', 'namliwala']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I am mustafa namliwala\"\n",
    "text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words(\"english\"))\n",
    "# stops\n",
    "# here not , no, nor are also stopwords which can completely change the sentiment of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = [5,9,8,2,3,7,1,10,100,88]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 3, 4, 0, 5, 2, 1, 7, 9, 8], dtype=int64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.argsort(lis)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   5,   7,   8,   9,  10,  88, 100])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "88\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    print(lis[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "# Suppose we have the following padded batch of sequences:\n",
    "seqs = torch.tensor([\n",
    "    [1, 2, 3, 4, 5],  # length: 5\n",
    "    [6, 7, 8, 0, 0],  # length: 3, padded with zeros\n",
    "    [9, 10, 0, 0, 0]  # length: 2, padded with zeros\n",
    "], dtype=torch.float)\n",
    "\n",
    "lengths = torch.tensor([5, 3, 2])  # Lengths of the sequences before padding\n",
    "\n",
    "# Packing the padded sequences\n",
    "packed_seqs = pack_padded_sequence(seqs, lengths, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "# Now, packed_seqs is a PackedSequence object with two fields: .data and .batch_sizes\n",
    "print(packed_seqs.data)\n",
    "# Output: tensor([1., 6., 9., 2., 7., 10., 3., 8., 4., 5.])\n",
    "\n",
    "print(packed_seqs.batch_sizes)\n",
    "# Output: tensor([3, 3, 2, 1, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
